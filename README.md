# ğŸ©º Medical Insurance Cost Prediction â€” Supervised Learning Project

## ğŸ“Œ Project Overview

This project builds a **supervised regression model** to predict individual medical insurance charges based on demographic and lifestyle features. Using the [Medical Insurance Cost Dataset](https://www.kaggle.com/datasets/mirichoi0218/insurance), we explore data, engineer features, train multiple models, and interpret the results.

---

## ğŸ¯ Objective

Predict the **medical charges (`charges`)** billed by health insurance providers using the following features:

* `age` â€” Age of the individual
* `sex` â€” Gender (male/female)
* `bmi` â€” Body mass index
* `children` â€” Number of dependents
* `smoker` â€” Smoking status (yes/no)
* `region` â€” Residential region (northeast, northwest, southeast, southwest)

Performance is evaluated using **RMSE**, **MAE**, and **RÂ²**.

---

## ğŸ§ª Workflow

1. **Problem Definition** â€” Define prediction goal and success criteria
2. **Exploratory Data Analysis (EDA)** â€” Understand distributions, correlations, and feature relationships
3. **Data Preprocessing** â€” Handle categorical encoding and prepare data for modeling
4. **Model Training** â€” Train and evaluate:

   * Linear Regression
   * Ridge Regression
   * Random Forest Regressor
5. **Model Evaluation** â€” Compare models on test data
6. **Error Analysis & Interpretation** â€” Analyze residuals, subgroup performance, and feature importance
7. **Conclusion & Next Steps** â€” Summarize insights and propose improvements

---

## ğŸ“Š Results Summary

| Model             | Test RMSE | Test MAE | RÂ²     |
| ----------------- | --------- | -------- | ------ |
| Random Forest     | 4431.96   | 2441.49  | 0.8735 |
| Linear Regression | 5796.28   | 4181.19  | 0.7836 |
| Ridge Regression  | 5798.27   | 4187.30  | 0.7834 |

âœ… **Random Forest** achieved the best performance, capturing non-linear relationships and feature interactions.

---

## ğŸ” Key Insights

* **Smoking status**, **age**, and **BMI** are the most impactful features.
* Smokers have significantly higher predicted charges than non-smokers.
* Non-linear models significantly outperform linear baselines.

---

## ğŸš€ Next Steps

* Explore **gradient boosting** models for further improvements.
* Add **uncertainty estimation** and **calibration**.
* Conduct **fairness analysis** across multiple demographic subgroups.

---

## ğŸ§° Tech Stack

* **Python 3.11+**
* `numpy`, `pandas`, `matplotlib`
* `scikit-learn` for modeling and evaluation

---

## ğŸ“‚ Reproducibility

The notebook follows best practices:

* Modular and commented code
* `main()` entry point
* Matplotlib for all plots (one chart per figure)
* Consistent preprocessing via `Pipeline` and `ColumnTransformer`

---

### ğŸ“œ License

This project is for educational purposes and distributed under the MIT License.
